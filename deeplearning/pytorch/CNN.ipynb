{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563eac08",
   "metadata": {},
   "source": [
    "# Convoultion\n",
    " - convoultion : 이미지 위의 stride 값 만큼 gilter를 이동하여, 겹쳐지는 부분의 각 원소의 값을 곱해서 모든 곱을 출력으로 하는 연산\n",
    " - input을 filter를 통해서 연산하는 것.  \n",
    " - stride: filter를 한번에 얼마나 이동하는가?\n",
    " - padding: input data 주변에 숫자을 채워넣는것. ex) Zero padding: 주변 1칸에 0씩 다 넣는다.\n",
    " \n",
    " ## 입력의 형태\n",
    " - input type : torch.Tensor\n",
    " - input shape : ( N(batch size) x C(channel) x H(height) x W (width)\n",
    " \n",
    " ## output size\n",
    " \n",
    " - output size = $\\frac{input size - filter size + (2 * padding)}{stride}$ \n",
    " \n",
    " ## pooling \n",
    " \n",
    " pooling: 이미지의 핵심적인 부분을 찾아내느것. filter 범위 내에서 제일 큰 값을 뽑아줌. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99b648f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:15.636543Z",
     "start_time": "2021-12-29T01:15:13.369798Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd3487a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:15.651540Z",
     "start_time": "2021-12-29T01:15:15.637547Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.nn.Conv2d(in_channels, out_channerls, kernel_size, stride, padding)\n",
    "#in_channels: input chnnel의 장수 , out_channerls : outchannel의 수. \n",
    "#kernel size: (x * n)x by n의 필터를 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cd252",
   "metadata": {},
   "source": [
    "# neuron and convolution\n",
    "- neron과 conv의 관계: convolution의 filter 값이 각 뉴런의 weight 값으로 들어감. 또 filter가 지나가는 원 데이터의 값이 input으로 들어감. \n",
    "- cov filter도 bias를 가질 수 있음. 따라서 input * filter의 summation + bias가 output으로 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60204f",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "- average pooling: 특정 필터(ex 2 * 2)내의 input에서 평균 값을 뽑아서 스칼라 값으로 변환 시킨다.\n",
    "- max pooling : 특정 필터(ex 2 * 2)내의 input에서 가장 큰 값을 뽑아서 스칼라 값으로 변환 시킨다.\n",
    "- pooling를 하는 이유\n",
    " 1) 이미지의 크기를 작게 만들기 위해. \n",
    " 2) fully cunnected layer의 연산을 대체하기 위해서 사용하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a7f616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.101646Z",
     "start_time": "2021-12-29T01:15:15.653541Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kernelsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c3a1671bf869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernelsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 실질적으로 kernel값만을 주요한 parameter로 사용한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kernelsize' is not defined"
     ]
    }
   ],
   "source": [
    "torch.nn.MaxPool2d(kernelsize)\n",
    "# 실질적으로 kernel값만을 주요한 parameter로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fd416",
   "metadata": {},
   "source": [
    "# cnn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127b517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.104650Z",
     "start_time": "2021-12-29T01:15:13.347Z"
    }
   },
   "outputs": [],
   "source": [
    "# toy example\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "conv1 = nn.Conv2d(1, 5, 5)\n",
    "pool = nn.MaxPool2d(2) # 2 by 2로 설정\n",
    "out = conv1(inputs)\n",
    "out2 = pool(out)\n",
    "out.size(), out2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516be01",
   "metadata": {},
   "source": [
    "# Covolution 연산\n",
    "\n",
    "- convolution 연산: g가 필터면 새로운 이미지가 기존의 이미지와 얼마나 겹치는 가에 따라서 출력값이 결정된다.\n",
    "- cross-correlation 연산: 핕터 g를 귀집지 않고, 기존의 이미지와 겹치는가를 비교함. \n",
    "- con와 crosscorrelation의 차이: 거의 없음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d6272",
   "metadata": {},
   "source": [
    "# 학습 단계\n",
    "- library 가져오기\n",
    "- GPU 사용 설정하고, random value를 위한 seed를 설정하라.\n",
    "- 학습에 사용되는 parameter인 leraning rate, training epochs, batch size 등등을 설정한다.\n",
    "- 데이터셋을 가져오고, 학습을 위해서 필요한 데이터 로더를 만든다. \n",
    "- 학습 모델 만들기( ex) torch.nn.Module\n",
    "- loss function(criterion)을 선택하고, optim을 설정한다.\n",
    "- model 학습과 loss check\n",
    "- 성능 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d1981",
   "metadata": {},
   "source": [
    "## toy example로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cdaf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.105643Z",
     "start_time": "2021-12-29T01:15:13.349Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = torch.Tensor(1,1,28,28)\n",
    "conv1 = nn.Conv2d(1, 32, 3, padding = 1) # 32개의 채널을 뽑을 때, kernel size는 3, padding은 1\n",
    "pool1 = nn.MaxPool2d(2, stride = 2)\n",
    "pool\n",
    "conv2 = nn.Conv2d(32, 64, kernel_size = 3, stride =1, padding = 1)\n",
    "pool2 = nn.MaxPool2d(2, stride = 2, padding = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b690de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.106644Z",
     "start_time": "2021-12-29T01:15:13.350Z"
    }
   },
   "outputs": [],
   "source": [
    "out = conv1(inputs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7e80b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.107643Z",
     "start_time": "2021-12-29T01:15:13.352Z"
    }
   },
   "outputs": [],
   "source": [
    "out = pool1(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc9f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.108643Z",
     "start_time": "2021-12-29T01:15:13.353Z"
    }
   },
   "outputs": [],
   "source": [
    "out = conv2(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51463b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.109645Z",
     "start_time": "2021-12-29T01:15:13.355Z"
    }
   },
   "outputs": [],
   "source": [
    "out = pool2(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec89a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.110645Z",
     "start_time": "2021-12-29T01:15:13.356Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch 사이즈\n",
    "out.size(0), out.size(1), out.size(2), out.size(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb6167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.111645Z",
     "start_time": "2021-12-29T01:15:13.357Z"
    }
   },
   "outputs": [],
   "source": [
    "out = out.view(out.size(0), -1)# batch 사이즈는 그대로 두고, 전체를 flatten하게 만들어준다.\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7ea1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.112645Z",
     "start_time": "2021-12-29T01:15:13.358Z"
    }
   },
   "outputs": [],
   "source": [
    "fc = nn.Linear(3136, 10)\n",
    "out = fc(out)\n",
    "out.shape # batch size에 맞게 만들어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5727e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.113644Z",
     "start_time": "2021-12-29T01:15:13.360Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56162de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.114644Z",
     "start_time": "2021-12-29T01:15:13.361Z"
    }
   },
   "outputs": [],
   "source": [
    "## gpu 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394478d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.115647Z",
     "start_time": "2021-12-29T01:15:13.363Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "trainig_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd40a40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.117648Z",
     "start_time": "2021-12-29T01:15:13.364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mnist dataset\n",
    "\n",
    "mnist_train = dsets.MNIST(root = \"MNIST_data/\",\n",
    "                         train= True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download = True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root = \"MNIST_data\",\n",
    "                        train = False,\n",
    "                        transform = transforms.ToTensor(),\n",
    "                        download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9faa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.118646Z",
     "start_time": "2021-12-29T01:15:13.366Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True,\n",
    "                                         drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16638b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T01:15:16.119647Z",
     "start_time": "2021-12-29T01:15:13.367Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep.prob = 0.5\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride = 1, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_sixe = 3, stride = 1, padding = 1))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride = 2))\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride = 1, padding =1),\n",
    "        torch.nn.Relu(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride=2, padding = 1))\n",
    "        self.fc1 = torch.nn.Linear( 4 *4 * 128, 625, bias = True)\n",
    "        torch.nn.init.xavier_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63046538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
